{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm \n",
    "\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_reader(filename):\n",
    "    \"\"\"\n",
    "    @filename: ste, name of dataset to load\n",
    "    @does: reads the dataset from directory and coverts to matrix\n",
    "    @returnL numpy matrix\n",
    "    \"\"\"\n",
    "    return np.array(pd.read_csv(filename, header = None),dtype = np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.00632</th>\n",
       "      <th>18</th>\n",
       "      <th>2.31</th>\n",
       "      <th>0</th>\n",
       "      <th>0.538</th>\n",
       "      <th>6.575</th>\n",
       "      <th>65.2</th>\n",
       "      <th>4.09</th>\n",
       "      <th>1</th>\n",
       "      <th>296</th>\n",
       "      <th>15.3</th>\n",
       "      <th>396.9</th>\n",
       "      <th>4.98</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.00632   18   2.31  0  0.538  6.575  65.2    4.09  1  296  15.3   396.9  \\\n",
       "0    0.02731  0.0   7.07  0  0.469  6.421  78.9  4.9671  2  242  17.8  396.90   \n",
       "1    0.02729  0.0   7.07  0  0.469  7.185  61.1  4.9671  2  242  17.8  392.83   \n",
       "2    0.03237  0.0   2.18  0  0.458  6.998  45.8  6.0622  3  222  18.7  394.63   \n",
       "3    0.06905  0.0   2.18  0  0.458  7.147  54.2  6.0622  3  222  18.7  396.90   \n",
       "4    0.02985  0.0   2.18  0  0.458  6.430  58.7  6.0622  3  222  18.7  394.12   \n",
       "..       ...  ...    ... ..    ...    ...   ...     ... ..  ...   ...     ...   \n",
       "500  0.06263  0.0  11.93  0  0.573  6.593  69.1  2.4786  1  273  21.0  391.99   \n",
       "501  0.04527  0.0  11.93  0  0.573  6.120  76.7  2.2875  1  273  21.0  396.90   \n",
       "502  0.06076  0.0  11.93  0  0.573  6.976  91.0  2.1675  1  273  21.0  396.90   \n",
       "503  0.10959  0.0  11.93  0  0.573  6.794  89.3  2.3889  1  273  21.0  393.45   \n",
       "504  0.04741  0.0  11.93  0  0.573  6.030  80.8  2.5050  1  273  21.0  396.90   \n",
       "\n",
       "     4.98    24  \n",
       "0    9.14  21.6  \n",
       "1    4.03  34.7  \n",
       "2    2.94  33.4  \n",
       "3    5.33  36.2  \n",
       "4    5.21  28.7  \n",
       "..    ...   ...  \n",
       "500  9.67  22.4  \n",
       "501  9.08  20.6  \n",
       "502  5.64  23.9  \n",
       "503  6.48  22.0  \n",
       "504  7.88  11.9  \n",
       "\n",
       "[505 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.00632</th>\n",
       "      <th>18</th>\n",
       "      <th>2.31</th>\n",
       "      <th>0</th>\n",
       "      <th>0.538</th>\n",
       "      <th>6.575</th>\n",
       "      <th>65.2</th>\n",
       "      <th>4.09</th>\n",
       "      <th>1</th>\n",
       "      <th>296</th>\n",
       "      <th>15.3</th>\n",
       "      <th>396.9</th>\n",
       "      <th>4.98</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00632</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200283</td>\n",
       "      <td>0.406251</td>\n",
       "      <td>-0.056132</td>\n",
       "      <td>0.420934</td>\n",
       "      <td>-0.218978</td>\n",
       "      <td>0.352701</td>\n",
       "      <td>-0.379626</td>\n",
       "      <td>0.625395</td>\n",
       "      <td>0.582568</td>\n",
       "      <td>0.289393</td>\n",
       "      <td>-0.384838</td>\n",
       "      <td>0.455328</td>\n",
       "      <td>-0.388249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.200283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.534022</td>\n",
       "      <td>-0.042550</td>\n",
       "      <td>-0.516574</td>\n",
       "      <td>0.311835</td>\n",
       "      <td>-0.569524</td>\n",
       "      <td>0.664396</td>\n",
       "      <td>-0.311717</td>\n",
       "      <td>-0.314351</td>\n",
       "      <td>-0.391713</td>\n",
       "      <td>0.175319</td>\n",
       "      <td>-0.412894</td>\n",
       "      <td>0.360393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.31</th>\n",
       "      <td>0.406251</td>\n",
       "      <td>-0.534022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062350</td>\n",
       "      <td>0.764556</td>\n",
       "      <td>-0.391330</td>\n",
       "      <td>0.645543</td>\n",
       "      <td>-0.708848</td>\n",
       "      <td>0.594167</td>\n",
       "      <td>0.720561</td>\n",
       "      <td>0.380955</td>\n",
       "      <td>-0.356506</td>\n",
       "      <td>0.602737</td>\n",
       "      <td>-0.484126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.056132</td>\n",
       "      <td>-0.042550</td>\n",
       "      <td>0.062350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091134</td>\n",
       "      <td>0.091497</td>\n",
       "      <td>0.086461</td>\n",
       "      <td>-0.099109</td>\n",
       "      <td>-0.007907</td>\n",
       "      <td>-0.035965</td>\n",
       "      <td>-0.122570</td>\n",
       "      <td>0.049040</td>\n",
       "      <td>-0.054576</td>\n",
       "      <td>0.175364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.538</th>\n",
       "      <td>0.420934</td>\n",
       "      <td>-0.516574</td>\n",
       "      <td>0.764556</td>\n",
       "      <td>0.091134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302127</td>\n",
       "      <td>0.731461</td>\n",
       "      <td>-0.769220</td>\n",
       "      <td>0.611758</td>\n",
       "      <td>0.668141</td>\n",
       "      <td>0.188918</td>\n",
       "      <td>-0.380006</td>\n",
       "      <td>0.591262</td>\n",
       "      <td>-0.427295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.575</th>\n",
       "      <td>-0.218978</td>\n",
       "      <td>0.311835</td>\n",
       "      <td>-0.391330</td>\n",
       "      <td>0.091497</td>\n",
       "      <td>-0.302127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240211</td>\n",
       "      <td>0.205170</td>\n",
       "      <td>-0.209277</td>\n",
       "      <td>-0.291680</td>\n",
       "      <td>-0.355116</td>\n",
       "      <td>0.127754</td>\n",
       "      <td>-0.613734</td>\n",
       "      <td>0.695365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65.2</th>\n",
       "      <td>0.352701</td>\n",
       "      <td>-0.569524</td>\n",
       "      <td>0.645543</td>\n",
       "      <td>0.086461</td>\n",
       "      <td>0.731461</td>\n",
       "      <td>-0.240211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747872</td>\n",
       "      <td>0.456232</td>\n",
       "      <td>0.506527</td>\n",
       "      <td>0.261724</td>\n",
       "      <td>-0.273486</td>\n",
       "      <td>0.602782</td>\n",
       "      <td>-0.376932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.09</th>\n",
       "      <td>-0.379626</td>\n",
       "      <td>0.664396</td>\n",
       "      <td>-0.708848</td>\n",
       "      <td>-0.099109</td>\n",
       "      <td>-0.769220</td>\n",
       "      <td>0.205170</td>\n",
       "      <td>-0.747872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494797</td>\n",
       "      <td>-0.534492</td>\n",
       "      <td>-0.232560</td>\n",
       "      <td>0.291451</td>\n",
       "      <td>-0.497276</td>\n",
       "      <td>0.249895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.625395</td>\n",
       "      <td>-0.311717</td>\n",
       "      <td>0.594167</td>\n",
       "      <td>-0.007907</td>\n",
       "      <td>0.611758</td>\n",
       "      <td>-0.209277</td>\n",
       "      <td>0.456232</td>\n",
       "      <td>-0.494797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910202</td>\n",
       "      <td>0.463322</td>\n",
       "      <td>-0.444065</td>\n",
       "      <td>0.487608</td>\n",
       "      <td>-0.381690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.582568</td>\n",
       "      <td>-0.314351</td>\n",
       "      <td>0.720561</td>\n",
       "      <td>-0.035965</td>\n",
       "      <td>0.668141</td>\n",
       "      <td>-0.291680</td>\n",
       "      <td>0.506527</td>\n",
       "      <td>-0.534492</td>\n",
       "      <td>0.910202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460100</td>\n",
       "      <td>-0.441505</td>\n",
       "      <td>0.543435</td>\n",
       "      <td>-0.468543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.3</th>\n",
       "      <td>0.289393</td>\n",
       "      <td>-0.391713</td>\n",
       "      <td>0.380955</td>\n",
       "      <td>-0.122570</td>\n",
       "      <td>0.188918</td>\n",
       "      <td>-0.355116</td>\n",
       "      <td>0.261724</td>\n",
       "      <td>-0.232560</td>\n",
       "      <td>0.463322</td>\n",
       "      <td>0.460100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.176515</td>\n",
       "      <td>0.372148</td>\n",
       "      <td>-0.508411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396.9</th>\n",
       "      <td>-0.384838</td>\n",
       "      <td>0.175319</td>\n",
       "      <td>-0.356506</td>\n",
       "      <td>0.049040</td>\n",
       "      <td>-0.380006</td>\n",
       "      <td>0.127754</td>\n",
       "      <td>-0.273486</td>\n",
       "      <td>0.291451</td>\n",
       "      <td>-0.444065</td>\n",
       "      <td>-0.441505</td>\n",
       "      <td>-0.176515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.365637</td>\n",
       "      <td>0.333394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.98</th>\n",
       "      <td>0.455328</td>\n",
       "      <td>-0.412894</td>\n",
       "      <td>0.602737</td>\n",
       "      <td>-0.054576</td>\n",
       "      <td>0.591262</td>\n",
       "      <td>-0.613734</td>\n",
       "      <td>0.602782</td>\n",
       "      <td>-0.497276</td>\n",
       "      <td>0.487608</td>\n",
       "      <td>0.543435</td>\n",
       "      <td>0.372148</td>\n",
       "      <td>-0.365637</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.738187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.388249</td>\n",
       "      <td>0.360393</td>\n",
       "      <td>-0.484126</td>\n",
       "      <td>0.175364</td>\n",
       "      <td>-0.427295</td>\n",
       "      <td>0.695365</td>\n",
       "      <td>-0.376932</td>\n",
       "      <td>0.249895</td>\n",
       "      <td>-0.381690</td>\n",
       "      <td>-0.468543</td>\n",
       "      <td>-0.508411</td>\n",
       "      <td>0.333394</td>\n",
       "      <td>-0.738187</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0.00632        18      2.31         0     0.538     6.575      65.2  \\\n",
       "0.00632  1.000000 -0.200283  0.406251 -0.056132  0.420934 -0.218978  0.352701   \n",
       "18      -0.200283  1.000000 -0.534022 -0.042550 -0.516574  0.311835 -0.569524   \n",
       "2.31     0.406251 -0.534022  1.000000  0.062350  0.764556 -0.391330  0.645543   \n",
       "0       -0.056132 -0.042550  0.062350  1.000000  0.091134  0.091497  0.086461   \n",
       "0.538    0.420934 -0.516574  0.764556  0.091134  1.000000 -0.302127  0.731461   \n",
       "6.575   -0.218978  0.311835 -0.391330  0.091497 -0.302127  1.000000 -0.240211   \n",
       "65.2     0.352701 -0.569524  0.645543  0.086461  0.731461 -0.240211  1.000000   \n",
       "4.09    -0.379626  0.664396 -0.708848 -0.099109 -0.769220  0.205170 -0.747872   \n",
       "1        0.625395 -0.311717  0.594167 -0.007907  0.611758 -0.209277  0.456232   \n",
       "296      0.582568 -0.314351  0.720561 -0.035965  0.668141 -0.291680  0.506527   \n",
       "15.3     0.289393 -0.391713  0.380955 -0.122570  0.188918 -0.355116  0.261724   \n",
       "396.9   -0.384838  0.175319 -0.356506  0.049040 -0.380006  0.127754 -0.273486   \n",
       "4.98     0.455328 -0.412894  0.602737 -0.054576  0.591262 -0.613734  0.602782   \n",
       "24      -0.388249  0.360393 -0.484126  0.175364 -0.427295  0.695365 -0.376932   \n",
       "\n",
       "             4.09         1       296      15.3     396.9      4.98        24  \n",
       "0.00632 -0.379626  0.625395  0.582568  0.289393 -0.384838  0.455328 -0.388249  \n",
       "18       0.664396 -0.311717 -0.314351 -0.391713  0.175319 -0.412894  0.360393  \n",
       "2.31    -0.708848  0.594167  0.720561  0.380955 -0.356506  0.602737 -0.484126  \n",
       "0       -0.099109 -0.007907 -0.035965 -0.122570  0.049040 -0.054576  0.175364  \n",
       "0.538   -0.769220  0.611758  0.668141  0.188918 -0.380006  0.591262 -0.427295  \n",
       "6.575    0.205170 -0.209277 -0.291680 -0.355116  0.127754 -0.613734  0.695365  \n",
       "65.2    -0.747872  0.456232  0.506527  0.261724 -0.273486  0.602782 -0.376932  \n",
       "4.09     1.000000 -0.494797 -0.534492 -0.232560  0.291451 -0.497276  0.249895  \n",
       "1       -0.494797  1.000000  0.910202  0.463322 -0.444065  0.487608 -0.381690  \n",
       "296     -0.534492  0.910202  1.000000  0.460100 -0.441505  0.543435 -0.468543  \n",
       "15.3    -0.232560  0.463322  0.460100  1.000000 -0.176515  0.372148 -0.508411  \n",
       "396.9    0.291451 -0.444065 -0.441505 -0.176515  1.000000 -0.365637  0.333394  \n",
       "4.98    -0.497276  0.487608  0.543435  0.372148 -0.365637  1.000000 -0.738187  \n",
       "24       0.249895 -0.381690 -0.468543 -0.508411  0.333394 -0.738187  1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0.00632', '18', '2.31', '0', '0.538', '6.575', '65.2', '4.09', '1',\n",
       "       '296', '15.3', '396.9', '4.98', '24'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, X, y, learningRate, maxIterations, tolerance, gd = False):\n",
    "        np.random.RandomState(10)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.learningRate = learningRate\n",
    "        self.maxIterations = maxIterations\n",
    "        self.tolerance = tolerance\n",
    "        self.gd = gd\n",
    "        \n",
    "    def splitToTrainTest(self):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.3, random_state=0)\n",
    "        return X_train, X_test, y_train, y_test \n",
    "    \n",
    "    def add_x0(self, X):\n",
    "        # Adding column of 1 as y intercept to the matrix\n",
    "        return np.column_stack([np.ones([X.shape[0], 1]) , X])\n",
    "    \n",
    "    def normalize(self, X):\n",
    "        \n",
    "        mean = np.mean(X , 0)\n",
    "        std = np.std(X, 0)\n",
    "        \n",
    "        X_norm = (X - mean) / std        \n",
    "        X_norm = self.add_x0(X_norm) # Adding 1s after normalizing \n",
    "        \n",
    "        return X_norm, mean, std\n",
    "    \n",
    "    def normalizeTestData(self, X, train_mean, train_std):\n",
    "        X_norm = (X - train_mean) / train_std\n",
    "        X_norm = self.add_x0(X_norm)\n",
    "        \n",
    "        return X_norm\n",
    "    \n",
    "    \n",
    "    def rank(self, X, eps = 1e-12):\n",
    "        # eps is epsilon. THis is to check all the diagonal values in the matrix to make sure it is not zero \n",
    "        # Larger eps value, lower the rank\n",
    "        u, s, vh = np.linalg.svd(X)\n",
    "        return len([x for x in s if abs(x) > eps])\n",
    "    \n",
    "    def checkMatrix(self, X):\n",
    "        x_rank = np.linalg.matrix_rank(X)\n",
    "        \n",
    "        # checking if its Full rank\n",
    "        if x_rank == min(X.shape[0], X.shape[1]):\n",
    "            print(\"Matrix is full rank\")\n",
    "            self.fullRank = True\n",
    "        else:\n",
    "            print(\"Matrix is not full rank\")\n",
    "            self.fullRank = False\n",
    "            \n",
    "        \n",
    "    def checkInvertibility(self, X):\n",
    "        # if n > d then its low rank\n",
    "        if X.shape[0] > X.shape[1]:\n",
    "            self.lowRank = True\n",
    "            print(\"data is Low Rank\")\n",
    "        else: \n",
    "            self.lowRank = False\n",
    "            print(\"data is not Low Rank\")\n",
    "            \n",
    "    def closedFormSolution(self, X, y):\n",
    "        # theta = (Xt . X)inv . Xt . y\n",
    "        w = np.linalg.inv(X.T.dot(X).dot(X.T).dot(y))\n",
    "        return w\n",
    "    \n",
    "    def gradientDescent(self, X, y):\n",
    "        error_sequence = []\n",
    "        \n",
    "        last = float('inf')\n",
    "        \n",
    "        for i in tqdm(range(self.maxIterations)):            \n",
    "            self.w = self.w - self.learningRate * self.costDerivatives(X, y)\n",
    "            \n",
    "            # setting current error using standard sqd error \n",
    "            \n",
    "            cur = self.sse(X, y)\n",
    "            dif = last - cur \n",
    "            last = cur\n",
    "            \n",
    "            error_sequence.append(cur)\n",
    "            \n",
    "            if dif < self.tolerance:\n",
    "                print(\"Model Stopped\")\n",
    "                break\n",
    "                \n",
    "            # WE can add condition to check current w (thetha) with the previous value of w and if it is below tolerance then we can stop \n",
    "            # This solution is easier\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \n",
    "        return X.dot(self.w)\n",
    "    \n",
    "    def sse(self, X, y):\n",
    "        \n",
    "        y_hat = self.predict(X)\n",
    "        return ((y_hat - y) ** 2).sum()\n",
    "        \n",
    "    def costFunction(self, X, y):\n",
    "        \n",
    "        return self.sse(X, y) / 2\n",
    "    \n",
    "    def costDerivatives(self, X, y):\n",
    "        # \n",
    "        y_hat = self.predict(X)        \n",
    "        return (y_hat - y).dot(X)\n",
    "    \n",
    "    def runModel(self):\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.splitToTrainTest()\n",
    "        \n",
    "        self.X_train, self.mean, self.std = self.normalize(self.X_train)\n",
    "        self.X_test = self.normalizeTestData(self.X_test, self.mean, self.std)\n",
    "        \n",
    "        self.checkMatrix(self.X_train)\n",
    "        self.checkInvertibility(self.X_train)\n",
    "        \n",
    "        if self.fullRank and not self.lowRank and self.X_train.shape[0] < 10000 and not self.gd: \n",
    "            \n",
    "            print(\"Solving using closed form solution\")\n",
    "            self.w = self.closedFormSolution(self.X_train, self.y_train)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            print(\"Solving using gradient descent\")\n",
    "            self.w = np.ones(self.X_train.shape[1], dtype = np.float64) * 0\n",
    "            self.gradientDescent(self.X_train, self.y_train)\n",
    "            \n",
    "            print(self.w)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression(df.values[:, 0:-1], df.values[:,-1], maxIterations=1000,\n",
    "                    learningRate=0.00001, tolerance=0.0000001, gd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 18456.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix is full rank\n",
      "data is Low Rank\n",
      "Solving using gradient descent\n",
      "[ 2.22660997e+01 -6.91152511e-01  5.70453434e-01 -2.32485602e-01\n",
      "  8.03819341e-01 -8.11656530e-01  3.17210361e+00  1.63935674e-02\n",
      " -1.66621383e+00  5.85293956e-01 -3.57727347e-01 -2.08078459e+00\n",
      "  6.55888273e-01 -3.39105590e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "regression.runModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression(df.values[:, 0:-1], df.values[:,-1], maxIterations=100,\n",
    "                    learningRate=0.00001, tolerance=0.0000001, gd=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 12297.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix is full rank\n",
      "data is Low Rank\n",
      "Solving using gradient descent\n",
      "[ 6.83115257 -0.50026466  0.47358678 -0.55284998  0.49126803 -0.43650848\n",
      "  1.49935507 -0.36253545 -0.01459749 -0.33361321 -0.52540914 -1.04735738\n",
      "  0.44381934 -1.40590858]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "regression.runModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand the relationship between error rate and learning rate to get a smooth gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
